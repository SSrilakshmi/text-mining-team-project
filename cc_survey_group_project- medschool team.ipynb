{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer\n",
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "import spacy\n",
    "from elasticsearch import helpers, Elasticsearch\n",
    "import csv\n",
    "import nltk\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from textblob import Word\n",
    "from itertools import islice\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define files\n",
    "filename1 = 'C://Users//annac//Desktop//DAPT//Text Mining//TM Group Project//RawSurveyData2019.csv'\n",
    "filename2 = 'C://Users//annac//Desktop//DAPT//Text Mining//TM Group Project//SurveyData2016-2018.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in csv's as a dataframe using pandas\n",
    "newdata = pd.read_csv(filename1)\n",
    "olddata = pd.read_csv(filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view data\n",
    "newdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view data\n",
    "olddata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define stop words and columns for newdata\n",
    "newdata = pd.DataFrame(newdata)\n",
    "\n",
    "#rename columns\n",
    "newdata.columns = [\"date_opened\",\"category\",\"cc_rating\",\"resolved\", \"contact_customer\", \"cc_comments\",\"eva_rating\", \"eva_comments\", \"cc_specialist\"]\n",
    "\n",
    "#define stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "#define punctuation for removal\n",
    "punc = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'm having difficulty with the below code to pull out columns 6 & 8. The current code [6:8] is targeting a range. I tried [x,x] but getting error \"invalid syntax\". The goal is to run the following code on the 2 text fields of survery responses (cc_comments & eva_comments), and generate sentiment and polarity scores on them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through the columns in newdata, minus the first two\n",
    "for col in newdata.columns[6:8]:\n",
    "#create a new column for each sentiment, polarity and subjectivity, in the loop that stores sentiment values\n",
    "    newdata[col+'_polarity_score'] = newdata[col].apply(lambda x: TextBlob(x).sentiment.polarity if np.all(pd.notnull(x)) else x)\n",
    "    newdata[col+'_subjectivity_score'] = newdata[col].apply(lambda x: TextBlob(x).sentiment.subjectivity if np.all(pd.notnull(x)) else x)\n",
    "\n",
    "#convert strings to lowercase and divide words into objects in a list\n",
    "    newdata[col] = newdata[col].str.lower().str.split()\n",
    "\n",
    "#check if each word is a stopword\n",
    "    newdata[col] = newdata[col].apply(lambda x: [item for item in x if item not in stop] if np.all(pd.notnull(x))  else x)\n",
    "    \n",
    "#check for punctuation\n",
    "    newdata[col] = newdata[col].apply(lambda x: [item for item in x if item not in punc] if np.all(pd.notnull(x))  else x)\n",
    "\n",
    "#convert each phrase back into a single string (necessary for textblob to work - you could also put these in separate columns)\n",
    "    newdata[col] = newdata[col].apply(lambda x: ' '.join(x) if np.all(pd.notnull(x))  else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on above code: we can visit stemming if needed because I found this was an issue with the other dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "newdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to change [no answer entered] to NA's\n",
    "newdata = newdata.replace({'[no answer entered]': np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are 2 versions- [No Answer Entered] (caps) also needs to be replaced with NaN\n",
    "newdata = newdata.replace({'[No Answer Entered]': np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign new columns with interpretations of the sentiment and polarity scores. This was helpful to make charts in Kibana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on cc_comments assign positive, negative, or neutral to polarity in a new column\n",
    "newdata.loc[newdata.cc_comments_polarity_score < 0, 'cc_sentiment'] = 'negative' \n",
    "newdata.loc[newdata.cc_comments_polarity_score == 0, 'cc_sentiment'] = 'neutral' \n",
    "newdata.loc[newdata.cc_comments_polarity_score > 0, 'cc_sentiment'] = 'positive'\n",
    "\n",
    "#on eva_comments assign positive, negative, or neutral to polarity in a new column. \n",
    "newdata.loc[newdata.eva_comments_polarity_score < 0, 'eva_sentiment'] = 'negative' \n",
    "newdata.loc[newdata.eva_comments_polarity_score == 0, 'eva_sentiment'] = 'neutral' \n",
    "newdata.loc[newdata.eva_comments_polarity_score > 0, 'eva_sentiment'] = 'positive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on cc_comments assign objective or subjective to subjectivity in a new column based on midpoint between 0-1.\n",
    "newdata.loc[newdata.cc_comments_subjectivity_score <= 0.5, 'cc_subjectivity'] = 'objective' \n",
    "newdata.loc[newdata.cc_comments_subjectivity_score > 0.5, 'cc_subjectivity'] = 'subjective'\n",
    "\n",
    "#on eva_comments assign objective or subjective to subjectivity in a new column based on midpoint between 0-1.\n",
    "newdata.loc[newdata.eva_comments_subjectivity_score <= 0.5, 'eva_subjectivity'] = 'objective' \n",
    "newdata.loc[newdata.eva_comments_subjectivity_score > 0.5, 'eva_subjectivity'] = 'subjective'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do we need to subset each question to remove NaN's? It would make a cleaner set to analyze. I've done that to create a dataset for each question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select columns and coll it \"newdata_cc\"\n",
    "newdata_cc = newdata[['date_opened','category', 'resolved','cc_rating', 'cc_comments', 'cc_comments_polarity_score', 'cc_comments_sentiment_score', 'cc_sentiment', 'cc_subjectivity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check subset\n",
    "newdata_cc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop na rows for newdata_cc_comments\n",
    "newdata_cc = newdata_cc.dropna()\n",
    "\n",
    "newdata_cc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repeat subset for second survey question eva_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select columns and call it newdata_eva\n",
    "newdata_eva = newdata[['date_opened','category', 'resolved','eva_rating', 'eva_comments', 'eva_comments_polarity_score', 'eva_comments_sentiment_score', 'eva_sentiment', 'eva_subjectivity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check subset\n",
    "newdata_eva.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop na rows for newdata_cc_comments\n",
    "newdata_eva = newdata_eva.dropna()\n",
    "\n",
    "newdata_eva.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export both question sets as a csv for elasticsearch\n",
    "newdata_cc.to_csv(r'C://Users//annac//Desktop//DAPT//Text Mining//newdata_cc.csv', index = False)\n",
    "newdata_eva.to_csv(r'C://Users//annac//Desktop//DAPT//Text Mining//newdata_eva.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this indexing in Kibana. This must be entered into Kibana under the \"wrench\" tool. \n",
    "#NOT CODE TO RUN IN PYTHON\n",
    "\n",
    "PUT /q1\n",
    "{\n",
    "   \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"std_english\": { \n",
    "          \"type\":      \"standard\",\n",
    "          \"stopwords\": \"_english_\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"resp_id\":    { \"type\": \"keyword\" },  \n",
    "      \"q1\":  { \"type\": \"text\" ,\"analyzer\": \"standard\", \"fielddata\": true }, \n",
    "      \"q1_polarity_score\":   { \"type\": \"integer\"  },     \n",
    "      \"q1_subjectivity_score\":   { \"type\": \"integer\"  },\n",
    "      \"sentiment\":    { \"type\": \"keyword\" },\n",
    "      \"subjectivity\":    { \"type\": \"keyword\" }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "#Once you enter this in Kibana, THEN you can run the below code to push the data in and it will index properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code used to push to elasticsearch (after index mapping above is set in Kibana)\n",
    "from elasticsearch import helpers, Elasticsearch\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('q1.csv') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    helpers.bulk(es, reader, index='q1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can repeat this code if we want to for the \"olddata\" file we imported which is from 2016-2018. NOTE: this dataset only has 1 survey question on Customer Care comments (no eva comments- that was added in 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once we finalize the code and all of us get the data into kibana, we can make some visualizations and screen shot them. I can show you that. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
